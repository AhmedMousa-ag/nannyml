{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de80d908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nannyml as nml\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "# 10 reference periods\n",
    "# 10 analysis periods\n",
    "# Days/week * Hours/day * events/hour\n",
    "DPP = 7*24*12\n",
    "\n",
    "np.random.seed(23)\n",
    "s1 = np.random.randn(DPP*20)\n",
    "x1 = s1 + np.random.randn(DPP*20)/8\n",
    "x2 = s1 + np.random.randn(DPP*20)/8\n",
    "x3 = np.random.randn(DPP*20)/8\n",
    "xdat = np.array([x1, x2, x3]).T\n",
    "\n",
    "rot = Rotation.from_euler('z', 90, degrees=True)\n",
    "\n",
    "# following matrix multiplication implementation, we need a 3xN data matrix hence we transpose\n",
    "ydat = np.matmul(rot.as_matrix(), xdat.T).T\n",
    "\n",
    "# create overall array that has drifted and not drifted subsets.\n",
    "# drift is sudden and affects last 5 weeks\n",
    "dataar = np.concatenate(\n",
    "    (xdat[:-5*DPP], ydat[-5*DPP:]),\n",
    "    axis=0\n",
    ")\n",
    "\n",
    "# convert data to dataframe\n",
    "datadf = pd.DataFrame(dataar, columns=['feature1', 'feature2', 'feature3'])\n",
    "\n",
    "# add \"timestamp\" column\n",
    "datadf = datadf.assign(ordered = pd.date_range(start='1/6/2020', freq='5min', periods=20*DPP))\n",
    "\n",
    "# Adding helper column - duplicates date range functionality\n",
    "datadf['week'] = datadf.ordered.dt.isocalendar().week - 1\n",
    "# Adding partition column\n",
    "datadf['partition'] = 'reference'\n",
    "datadf.loc[datadf.week >= 11, ['partition']] = 'analysis'\n",
    "\n",
    "# Assign random predictions and targets (we won't be using them but they are needed for NannyML)\n",
    "datadf = datadf.assign(y_pred_proba = np.random.rand(DPP*20))\n",
    "datadf = datadf.assign(y_true = np.random.randint(2, size=DPP*20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75822ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's construct a dataframe for visuzlization purposes\n",
    "dat1 = datadf.loc[datadf.week == 10, ['feature1', 'feature2']][:1500]\n",
    "dat1['week'] = 10\n",
    "dat2 = datadf.loc[datadf.week == 16, ['feature1', 'feature2']][:1500]\n",
    "dat2['week'] = 16\n",
    "data_sample = pd.concat([dat1, dat2], ignore_index=True)\n",
    "\n",
    "# let's plot\n",
    "colors = nml.plots.colors.Colors\n",
    "figure = sns.jointplot(\n",
    "    data=data_sample,\n",
    "    x=\"feature1\",\n",
    "    y=\"feature2\",\n",
    "    hue=\"week\",\n",
    "    palette=[colors.BLUE_SKY_CRAYOLA.value, colors.RED_IMPERIAL.value]\n",
    ")\n",
    "figure.fig.suptitle('Data Distributions before and after rotation drift')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a45014",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adc1b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first create the analysis and reference datasets NannyML needs.\n",
    "reference = datadf.loc[datadf['partition'] == 'reference'].reset_index(drop=True)\n",
    "reference.drop(['week', 'partition'], axis=1, inplace=True)\n",
    "analysis = datadf.loc[datadf['partition'] == 'analysis'].reset_index(drop=True)\n",
    "analysis.drop(['y_true', 'week', 'partition'], axis=1, inplace=True)\n",
    "\n",
    "feature_column_names = ['feature1', 'feature2', 'feature3']\n",
    "\n",
    "# Let's instantiate and calibrate univariate drift\n",
    "univariate_calculator = nml.UnivariateStatisticalDriftCalculator(\n",
    "    feature_column_names=feature_column_names,\n",
    "    timestamp_column_name='ordered',\n",
    "    chunk_size=DPP\n",
    ")\n",
    "univariate_calculator.fit(reference_data=reference)\n",
    "\n",
    "# let's compute (and visualize) results across all the dataset.\n",
    "univariate_results = univariate_calculator.calculate(data=analysis)\n",
    "for feature in feature_column_names:\n",
    "    figure = univariate_results.plot(\n",
    "        kind='feature_distribution',\n",
    "        feature=feature,\n",
    "        plot_reference=True\n",
    "    )\n",
    "    figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144e94cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compute multivariate drift\n",
    "rcerror_calculator = nml.DataReconstructionDriftCalculator(\n",
    "    feature_column_names=feature_column_names,\n",
    "    timestamp_column_name='ordered',\n",
    "    chunk_size=DPP\n",
    ").fit(reference_data=reference)\n",
    "# let's compute results for analysis period\n",
    "rcerror_results = rcerror_calculator.calculate(data=analysis)\n",
    "\n",
    "# let's visualize results across all the dataset\n",
    "figure = rcerror_results.plot(plot_reference=True)\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc33d4df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597e2d26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
